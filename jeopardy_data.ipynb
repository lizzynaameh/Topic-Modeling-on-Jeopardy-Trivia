{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064226e0-ec92-46e8-b209-32335188aa0b",
   "metadata": {},
   "source": [
    "# Jeopardy! Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62448092-9d61-4214-8e5b-ff7be8dc69e4",
   "metadata": {},
   "source": [
    "Source of Data:\n",
    "* https://drive.google.com/file/d/0BwT5wj_P7BKXUl9tOUJWYzVvUjA/view?resourcekey=0-uFrn8bQkUfSCvJlmtKGCdQ\n",
    "* https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c31bd16-03e0-4155-9132-b46286476d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "#!pip install fuzzywuzzy\n",
    "#!pip install python-Levenshtein\n",
    "\n",
    "# data handling\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# string manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.decomposition import NMF\n",
    "# nltk.download('stopwords') #run this once\n",
    "\n",
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04732c-2eac-4442-88df-a3f01885d7a5",
   "metadata": {},
   "source": [
    "## 1. Construct Dataset of Jeopardy Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8be8dcc9-2cae-4f70-b4eb-b75e8a768204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216930 entries, 0 to 216929\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Show Number  216930 non-null  int64 \n",
      " 1    Air Date    216930 non-null  object\n",
      " 2    Round       216930 non-null  object\n",
      " 3    Category    216930 non-null  object\n",
      " 4    Value       216930 non-null  object\n",
      " 5    Question    216930 non-null  object\n",
      " 6    Answer      216928 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./JEOPARDY_CSV.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a47d46a1-53f3-4d73-9517-24c36d849e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>HISTORY For the last 8 years of his life, Gali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES No. 2: 1912 Ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT... The city of Yuma i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>THE COMPANY LINE In 1963, live on \"The Art Lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES Signer of the Dec. of Inde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   show_number   air_date      round                         category value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            question      answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                                text  \n",
       "0  HISTORY For the last 8 years of his life, Gali...  \n",
       "1  ESPN's TOP 10 ALL-TIME ATHLETES No. 2: 1912 Ol...  \n",
       "2  EVERYBODY TALKS ABOUT IT... The city of Yuma i...  \n",
       "3  THE COMPANY LINE In 1963, live on \"The Art Lin...  \n",
       "4  EPITAPHS & TRIBUTES Signer of the Dec. of Inde...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "\n",
    "#convert air_date to datetime\n",
    "df.air_date = pd.to_datetime(df.air_date)\n",
    "\n",
    "#remove clues with media attachments, missing values\n",
    "df = df[~df.question.str.contains('seen here|[Cc]lue|href|filler')].reset_index(drop=True)\n",
    "df = df.dropna(axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#create new column for processed text, while retaining original clues\n",
    "df['text'] = df['category'] + ' ' + df['question'] + ' ' + df['answer'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca3bc900-8982-4119-b102-47927e87e31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert value to ints, and round to values in [200, 400, 600, ... 1800] \n",
    "df.value = df.value.str.replace('$','').str.replace(',', '').str.replace('None', '200').astype(int) \n",
    "\n",
    "def replace_values(n):\n",
    "    if n in range(200, 2000, 200):\n",
    "        return n\n",
    "    for value in range(200, 2000, 200):\n",
    "        if n < value:\n",
    "            return value\n",
    "    return 1800\n",
    "\n",
    "df.value = df.value.map(replace_values)\n",
    "sorted(df.value.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e5feb39-3288-470b-af44-eb3ddaf8a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203485, 8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eecfd52-922f-47f1-b746-9b6ffb89215e",
   "metadata": {},
   "source": [
    "## 2. Text-Cleaning (URLs, HTML tags, digits, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c15336dd-c885-4be9-9f78-af3aebb8dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, \n",
    "    remove punctuation and remove words containing numbers, remove line breaks.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
    "    text = re.sub('[''\"\"]', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub('\\.\\.\\.|\\\\|\\\\n|&|:|;|\\'|\\$|!', '', text)\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    return text\n",
    "\n",
    "df.text = df.text.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4d4ec2d-ab81-45c4-9dda-0fc0c8fa0878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history for the last   years of his life, galileo was under house arrest for espousing this mans theory copernicus',\n",
       " 'espns top   all-time athletes no.     olympian football star at carlisle indian school   mlb seasons with the reds, giants  braves jim thorpe',\n",
       " 'everybody talks about it the city of yuma in this state has a record average of  ,  hours of sunshine each year arizona',\n",
       " 'the company line in  , live on the art linkletter show, this company served its billionth burger mcdonalds',\n",
       " 'epitaphs  tributes signer of the dec. of indep., framer of the constitution of mass., second president of the united states john adams']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view a sample of cleaned text \n",
    "df.text.to_list()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b82562-b863-460e-92bf-9a6a33012c6b",
   "metadata": {},
   "source": [
    "## 3. Tokenization , Removal of Digits, Stop Words and Punctuations\n",
    "Further preprocessing of the new feature ‘text’\n",
    "NLTK (Natural Language Toolkit) is one of the best library for preprocessing text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4349b68c-1948-4da1-acad-c9a0771dfe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    #tokenize and lemmatize corpus\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [re.sub('[%s]' % re.escape(string.punctuation), '', token) for token in tokens]\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    #define stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    new_stopwords=['jpg', 'blank', 'wmv', 'also', 'used', 'made', 'like', 'one', 'wa', 'ha', 'st', 'name'] \n",
    "    stop_words.extend(new_stopwords)  \n",
    "    \n",
    "    #filter for nouns, minimum 2 letters long \n",
    "    #options to add adjectives:  (or pos == 'JJ' or pos == 'JJR' or pos == 'JJS')\n",
    "    nouns = []\n",
    "    for word,pos in nltk.pos_tag(lemmas):\n",
    "         if ((pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS') and (word not in stop_words) and (len(word) > 1)):\n",
    "                nouns.append(word)\n",
    "    \n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "271f4d0d-2e53-4390-b36a-9e3903d4e477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203485, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e040f-03d4-4b9a-8c27-68700bc98904",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Vectorizer to generate Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67b16009-0462-42be-ab0c-cd761aa6f66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203485, 1094)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_tfidf = TfidfVectorizer(analyzer=preprocess_text, max_df = 0.15, min_df = .001)\n",
    "doc_word = cv_tfidf.fit_transform(df.text)\n",
    "doc_word = pd.DataFrame(doc_word.toarray(), columns=cv_tfidf.get_feature_names())\n",
    "doc_word.to_pickle(\"dtm.pkl\")\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80ad64e2-82f1-4d58-b6ac-fbd1a936ff40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbrev</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abraham</th>\n",
       "      <th>academy</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activity</th>\n",
       "      <th>actor</th>\n",
       "      <th>actress</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>wwii</th>\n",
       "      <th>yankee</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "      <th>zealand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1094 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abbrev  abbreviation  abraham  academy  act  action  activity  actor  \\\n",
       "0     0.0           0.0      0.0      0.0  0.0     0.0       0.0    0.0   \n",
       "1     0.0           0.0      0.0      0.0  0.0     0.0       0.0    0.0   \n",
       "2     0.0           0.0      0.0      0.0  0.0     0.0       0.0    0.0   \n",
       "3     0.0           0.0      0.0      0.0  0.0     0.0       0.0    0.0   \n",
       "4     0.0           0.0      0.0      0.0  0.0     0.0       0.0    0.0   \n",
       "\n",
       "   actress   ad  ...  writer  wwii  yankee      year  york  youll  youre  \\\n",
       "0      0.0  0.0  ...     0.0   0.0     0.0  0.341982   0.0    0.0    0.0   \n",
       "1      0.0  0.0  ...     0.0   0.0     0.0  0.000000   0.0    0.0    0.0   \n",
       "2      0.0  0.0  ...     0.0   0.0     0.0  0.320805   0.0    0.0    0.0   \n",
       "3      0.0  0.0  ...     0.0   0.0     0.0  0.000000   0.0    0.0    0.0   \n",
       "4      0.0  0.0  ...     0.0   0.0     0.0  0.000000   0.0    0.0    0.0   \n",
       "\n",
       "   youth  youve  zealand  \n",
       "0    0.0    0.0      0.0  \n",
       "1    0.0    0.0      0.0  \n",
       "2    0.0    0.0      0.0  \n",
       "3    0.0    0.0      0.0  \n",
       "4    0.0    0.0      0.0  \n",
       "\n",
       "[5 rows x 1094 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doc-term matrix \n",
    "doc_word.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e14aa-e307-4900-b640-b9e54c4bd099",
   "metadata": {},
   "source": [
    "## 5. Matrix Factorization with NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8edc9738-033e-4a1f-a409-67f74b0f84a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203485, 13)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doc-topic matrix, H matrix\n",
    "nmf_model = NMF(n_components=13,random_state=1)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9ad384a-87e2-4afa-8340-d789ac6af8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1094)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dce6939c-6212-4319-b9d0-215edb5dd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the words that make up each topic\n",
    "words = cv_tfidf.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-10:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words_df = pd.DataFrame(topic_words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6b22f0e-01e7-4fd8-b222-10e4f6a0b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Cities</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Film &amp; TV</th>\n",
       "      <th>U.S. Hodgepodge</th>\n",
       "      <th>Magazines</th>\n",
       "      <th>History</th>\n",
       "      <th>Science</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Words</th>\n",
       "      <th>Literature</th>\n",
       "      <th>People</th>\n",
       "      <th>Culture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>city</td>\n",
       "      <td>country</td>\n",
       "      <td>film</td>\n",
       "      <td>state</td>\n",
       "      <td>time</td>\n",
       "      <td>world</td>\n",
       "      <td>type</td>\n",
       "      <td>capital</td>\n",
       "      <td>letter</td>\n",
       "      <td>book</td>\n",
       "      <td>man</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phrase</td>\n",
       "      <td>york</td>\n",
       "      <td>island</td>\n",
       "      <td>movie</td>\n",
       "      <td>island</td>\n",
       "      <td>rhyme</td>\n",
       "      <td>war</td>\n",
       "      <td>food</td>\n",
       "      <td>world</td>\n",
       "      <td>term</td>\n",
       "      <td>author</td>\n",
       "      <td>john</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>term</td>\n",
       "      <td>river</td>\n",
       "      <td>music</td>\n",
       "      <td>tv</td>\n",
       "      <td>university</td>\n",
       "      <td>york</td>\n",
       "      <td>history</td>\n",
       "      <td>science</td>\n",
       "      <td>birthplace</td>\n",
       "      <td>number</td>\n",
       "      <td>woman</td>\n",
       "      <td>president</td>\n",
       "      <td>president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meaning</td>\n",
       "      <td>home</td>\n",
       "      <td>geography</td>\n",
       "      <td>title</td>\n",
       "      <td>college</td>\n",
       "      <td>day</td>\n",
       "      <td>island</td>\n",
       "      <td>term</td>\n",
       "      <td>river</td>\n",
       "      <td>alphabet</td>\n",
       "      <td>title</td>\n",
       "      <td>people</td>\n",
       "      <td>century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>origin</td>\n",
       "      <td>museum</td>\n",
       "      <td>france</td>\n",
       "      <td>star</td>\n",
       "      <td>california</td>\n",
       "      <td>celebrity</td>\n",
       "      <td>leader</td>\n",
       "      <td>bird</td>\n",
       "      <td>geography</td>\n",
       "      <td>men</td>\n",
       "      <td>novel</td>\n",
       "      <td>george</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>latin</td>\n",
       "      <td>place</td>\n",
       "      <td>language</td>\n",
       "      <td>character</td>\n",
       "      <td>president</td>\n",
       "      <td>song</td>\n",
       "      <td>geography</td>\n",
       "      <td>fruit</td>\n",
       "      <td>lie</td>\n",
       "      <td>end</td>\n",
       "      <td>character</td>\n",
       "      <td>history</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>come</td>\n",
       "      <td>port</td>\n",
       "      <td>president</td>\n",
       "      <td>role</td>\n",
       "      <td>river</td>\n",
       "      <td>magazine</td>\n",
       "      <td>ii</td>\n",
       "      <td>water</td>\n",
       "      <td>museum</td>\n",
       "      <td>symbol</td>\n",
       "      <td>century</td>\n",
       "      <td>song</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>language</td>\n",
       "      <td>university</td>\n",
       "      <td>people</td>\n",
       "      <td>song</td>\n",
       "      <td>park</td>\n",
       "      <td>sport</td>\n",
       "      <td>nation</td>\n",
       "      <td>body</td>\n",
       "      <td>idea</td>\n",
       "      <td>form</td>\n",
       "      <td>literature</td>\n",
       "      <td>music</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>something</td>\n",
       "      <td>geography</td>\n",
       "      <td>china</td>\n",
       "      <td>actor</td>\n",
       "      <td>texas</td>\n",
       "      <td>life</td>\n",
       "      <td>battle</td>\n",
       "      <td>life</td>\n",
       "      <td>province</td>\n",
       "      <td>synonym</td>\n",
       "      <td>john</td>\n",
       "      <td>century</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language      Cities  Countries  Film & TV U.S. Hodgepodge  Magazines  \\\n",
       "0       word        city    country       film           state       time   \n",
       "1     phrase        york     island      movie          island      rhyme   \n",
       "2       term       river      music         tv      university       york   \n",
       "3    meaning        home  geography      title         college        day   \n",
       "4     origin      museum     france       star      california  celebrity   \n",
       "5      latin       place   language  character       president       song   \n",
       "6       come        port  president       role           river   magazine   \n",
       "7   language  university     people       song            park      sport   \n",
       "8  something   geography      china      actor           texas       life   \n",
       "\n",
       "     History  Science    Capitals     Words  Literature     People    Culture  \n",
       "0      world     type     capital    letter        book        man       year  \n",
       "1        war     food       world      term      author       john        day  \n",
       "2    history  science  birthplace    number       woman  president  president  \n",
       "3     island     term       river  alphabet       title     people    century  \n",
       "4     leader     bird   geography       men       novel     george    history  \n",
       "5  geography    fruit         lie       end   character    history      sport  \n",
       "6         ii    water      museum    symbol     century       song     number  \n",
       "7     nation     body        idea      form  literature      music        war  \n",
       "8     battle     life    province   synonym        john    century       life  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topics for just nouns\n",
    "topics = ['Language', 'Cities', 'Countries', 'Film & TV', 'U.S. Hodgepodge', 'Magazines', 'History', 'Science', 'Capitals', 'Words', 'Literature', 'People', 'Culture']\n",
    "\n",
    "#different topics for nouns & adj\n",
    "#topics = ['Language', 'Cities', 'Potpourri', 'Countries', 'Potpourri', 'Film', 'Magazines', 'History', 'Literature', 'Science', 'Words', 'Television', 'Culture']\n",
    "\n",
    "topic_words_df.columns = topics\n",
    "topic_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a7b36-5fa3-4e46-af03-32f3c7b64078",
   "metadata": {},
   "source": [
    "### Topic-Terms Matrix (W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "436b5628-c975-48c2-be4d-7f9b7d187523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbrev</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abraham</th>\n",
       "      <th>academy</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activity</th>\n",
       "      <th>actor</th>\n",
       "      <th>actress</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>wwii</th>\n",
       "      <th>yankee</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "      <th>zealand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042264</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.061293</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.013412</td>\n",
       "      <td>0.000432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cities</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528522</td>\n",
       "      <td>0.067113</td>\n",
       "      <td>0.034140</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.014873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countries</th>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.014485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.013003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0.085465</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.111469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Film &amp; TV</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.060160</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.437880</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034488</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043235</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Hodgepodge</th>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168560</td>\n",
       "      <td>0.038255</td>\n",
       "      <td>0.035985</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1094 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   abbrev  abbreviation   abraham   academy       act  \\\n",
       "Language         0.000000      0.000000  0.000745  0.000000  0.042264   \n",
       "Cities           0.000000      0.000000  0.008201  0.014509  0.002382   \n",
       "Countries        0.001459      0.000983  0.000000  0.001138  0.007804   \n",
       "Film & TV        0.000799      0.002307  0.004894  0.011520  0.009789   \n",
       "U.S. Hodgepodge  0.009563      0.057734  0.006728  0.006190  0.009372   \n",
       "\n",
       "                   action  activity     actor   actress        ad  ...  \\\n",
       "Language         0.022097  0.012397  0.000492  0.000000  0.001055  ...   \n",
       "Cities           0.003746  0.001620  0.000000  0.001225  0.025534  ...   \n",
       "Countries        0.003550  0.001383  0.000283  0.004417  0.014485  ...   \n",
       "Film & TV        0.060160  0.002267  0.437880  0.231100  0.029976  ...   \n",
       "U.S. Hodgepodge  0.002567  0.001599  0.000000  0.001671  0.000000  ...   \n",
       "\n",
       "                   writer      wwii    yankee  year      york     youll  \\\n",
       "Language         0.018608  0.002838  0.001740   0.0  0.000000  0.017187   \n",
       "Cities           0.006236  0.007652  0.004101   0.0  0.528522  0.067113   \n",
       "Countries        0.004768  0.013003  0.000000   0.0  0.000000  0.047434   \n",
       "Film & TV        0.034488  0.011885  0.009390   0.0  0.043235  0.004467   \n",
       "U.S. Hodgepodge  0.002667  0.001596  0.002478   0.0  0.168560  0.038255   \n",
       "\n",
       "                    youre     youth     youve   zealand  \n",
       "Language         0.061293  0.010727  0.013412  0.000432  \n",
       "Cities           0.034140  0.003825  0.000220  0.014873  \n",
       "Countries        0.085465  0.003385  0.006406  0.111469  \n",
       "Film & TV        0.042062  0.005355  0.007952  0.002090  \n",
       "U.S. Hodgepodge  0.035985  0.002667  0.002982  0.000000  \n",
       "\n",
       "[5 rows x 1094 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Topic-terms matrix (W) with .components_\n",
    "components_df = pd.DataFrame(nmf_model.components_, columns=cv_tfidf.get_feature_names(), index=topics)\n",
    "components_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "331dd66e-1e1f-4b9e-a743-463143afa039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to print top words per category with scores\n",
    "# for topic in components_df.index:\n",
    "#     tmp = components_df.loc[topic]\n",
    "#     print(f'Topic: {topic}')\n",
    "#     print('The words with the highest value are:')\n",
    "#     print(tmp.nlargest(10))\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd02b6-732d-4d6a-96d2-af217e50a303",
   "metadata": {},
   "source": [
    "### Topic-Document Matrix (H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8a96347-1e46-4b3b-ab88-b54e713818ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Cities</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Film &amp; TV</th>\n",
       "      <th>U.S. Hodgepodge</th>\n",
       "      <th>Magazines</th>\n",
       "      <th>History</th>\n",
       "      <th>Science</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Words</th>\n",
       "      <th>Literature</th>\n",
       "      <th>People</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00756</td>\n",
       "      <td>0.00118</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>0.05828</td>\n",
       "      <td>People</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.00814</td>\n",
       "      <td>0.00170</td>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.00309</td>\n",
       "      <td>Film &amp; TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03436</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05183</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05018</td>\n",
       "      <td>U.S. Hodgepodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.00119</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00675</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00319</td>\n",
       "      <td>0.00298</td>\n",
       "      <td>0.00348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00127</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.00780</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>People</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.05396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.00305</td>\n",
       "      <td>0.01656</td>\n",
       "      <td>0.00407</td>\n",
       "      <td>U.S. Hodgepodge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language   Cities  Countries  Film & TV  U.S. Hodgepodge  Magazines  \\\n",
       "0   0.00000  0.00007    0.00000    0.00000          0.00000    0.00000   \n",
       "1   0.00021  0.00037    0.00014    0.00814          0.00170    0.00112   \n",
       "2   0.00000  0.03436    0.00000    0.00000          0.05183    0.00000   \n",
       "3   0.00042  0.00119    0.00000    0.00675          0.00044    0.00319   \n",
       "4   0.00000  0.00000    0.00057    0.00174          0.05396    0.00000   \n",
       "\n",
       "   History  Science  Capitals    Words  Literature   People  Culture  \\\n",
       "0  0.00756  0.00118   0.00000  0.00000     0.00165  0.06570  0.05828   \n",
       "1  0.00059  0.00104   0.00000  0.00028     0.00061  0.00186  0.00309   \n",
       "2  0.00000  0.00000   0.00000  0.00000     0.00000  0.00000  0.05018   \n",
       "3  0.00298  0.00348   0.00000  0.00127     0.00182  0.00780  0.00320   \n",
       "4  0.00000  0.00000   0.00001  0.00013     0.00305  0.01656  0.00407   \n",
       "\n",
       "          Category  \n",
       "0           People  \n",
       "1        Film & TV  \n",
       "2  U.S. Hodgepodge  \n",
       "3           People  \n",
       "4  U.S. Hodgepodge  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at topic-document matrix\n",
    "H = pd.DataFrame(doc_topic.round(5),\n",
    "             #index = df.text,\n",
    "             columns = topics)\n",
    "\n",
    "#assign each document the appropriate topic by max value\n",
    "H['Category'] = H.idxmax(axis=1)\n",
    "H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0568e954-fc56-4d2e-a14b-4894b4a7069a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Literature         34364\n",
       "Film & TV          28373\n",
       "Science            23702\n",
       "People             23378\n",
       "History            19167\n",
       "U.S. Hodgepodge    15968\n",
       "Culture            13351\n",
       "Language           12681\n",
       "Magazines           8198\n",
       "Cities              7538\n",
       "Words               7406\n",
       "Countries           7037\n",
       "Capitals            2322\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#highest frequency meta-categories\n",
    "H.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1f6fd4c-b379-4196-b406-a2d4c52e838d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>history for the last   years of his life, gali...</td>\n",
       "      <td>People</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>espns top   all-time athletes no.     olympian...</td>\n",
       "      <td>Film &amp; TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>everybody talks about it the city of yuma in t...</td>\n",
       "      <td>U.S. Hodgepodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>the company line in  , live on the art linklet...</td>\n",
       "      <td>People</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>epitaphs  tributes signer of the dec. of indep...</td>\n",
       "      <td>U.S. Hodgepodge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   show_number   air_date      round                         category  value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY    200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES    200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...    200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE    200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES    200   \n",
       "\n",
       "                                            question      answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                                text         Category  \n",
       "0  history for the last   years of his life, gali...           People  \n",
       "1  espns top   all-time athletes no.     olympian...        Film & TV  \n",
       "2  everybody talks about it the city of yuma in t...  U.S. Hodgepodge  \n",
       "3  the company line in  , live on the art linklet...           People  \n",
       "4  epitaphs  tributes signer of the dec. of indep...  U.S. Hodgepodge  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(H, left_index=True, right_index=True).drop(columns = topics)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "debb461a-46d5-4b66-a1fe-a868f7eab40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532efb1-41a6-420f-9f42-e3e572884ce3",
   "metadata": {},
   "source": [
    "## 6. Random Question Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3d8b128-16ff-4a43-9592-c134fc67187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question from the category BEFORE & AFTER for 200:\n",
      "A vodka & tomato juice drink turns into a Texas-based cosmetics giant\n",
      "Answer: Bloody Mary Kay\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Generate random questions given meta-category or category, value:\n",
    "\n",
    "def generate_q(category, value, mc=True, df=df, sleep=2):\n",
    "    #filter dataset\n",
    "    if mc:\n",
    "        row = df[(df.Category == category) & (df.value == value)].sample(1)\n",
    "    else:\n",
    "        row = df[(df.category == category.upper()) & (df.value == value)].sample(1)\n",
    "    cat, val, q, a = row.category.to_list()[0], row.value.to_list()[0], row.question.to_list()[0], row.answer.to_list()[0]\n",
    "    print(f'Question from the category {cat} for {val}:')\n",
    "    print(q)\n",
    "    time.sleep(sleep)\n",
    "    print(f'Answer: {a}')\n",
    "    \n",
    "#testing \n",
    "generate_q('BEFORE & AFTER', 200, mc=False, sleep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebe7386e-0b2b-4cc6-ac13-266f42efca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question from the category LITERATURE for 200:\n",
      "This Nobel Prize winner dedicated \"The Waste Land\" to fellow poet Ezra Pound\n",
      "Answer: T.S. Eliot\n"
     ]
    }
   ],
   "source": [
    "# literature treated as a J-category\n",
    "generate_q('Literature', 200, mc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9caf09cc-4ed2-4468-afac-899ae95c2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question from the category BOGIE MEN for 200:\n",
      "Rick Blaine\n",
      "Answer: Casablanca\n"
     ]
    }
   ],
   "source": [
    "# literature treated as a meta-category\n",
    "generate_q('Literature', 200, sleep=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8c99b-521a-409d-83d4-58ea7f0831a8",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Add \"View More Options\" tab option to select... \n",
    "* years (slider)\n",
    "* by J-category (entry box that populates anticipated terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24531fef-23dd-4133-9313-f453bac29b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
